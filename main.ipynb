{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_cleaning import ParquetDataCleaner\n",
    "from src.data_processing import ParquetDataProcessor\n",
    "from src import utils\n",
    "import config\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Ejecuta el flujo de trabajo principal.\"\"\"\n",
    "data_info = utils.read_csv(config.CSV_FILE)\n",
    "\n",
    "# Filtrar el archivo train.csv por la palabra clave 'bird'\n",
    "filtered_csv_path = config.DATA_PATH + \"filtered_train.csv\"\n",
    "utils.filter_csv_by_sign(config.CSV_FILE, filtered_csv_path, \"time\")\n",
    "\n",
    "# Leer el CSV filtrado esto se comenta si se quiere procesar todas las palabras\n",
    "data_info = utils.read_csv(filtered_csv_path)\n",
    "# Crear las carpetas necesarias si no existen\n",
    "os.makedirs(config.CLEANED_DATA_PATH, exist_ok=True)\n",
    "os.makedirs(config.NPY_DATA_PATH, exist_ok=True)\n",
    "\n",
    "data_cleaner = ParquetDataCleaner()\n",
    "data_processor = ParquetDataProcessor()\n",
    "\n",
    "train_subjects_data = {}\n",
    "val_subjects_data = {}\n",
    "min_and_max = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_info.iterrows():\n",
    "    parquet_path = config.RAW_DATA_PATH + row[\"path\"]\n",
    "    cleaned_data = data_cleaner.clean(parquet_path)\n",
    "\n",
    "    # # Agregar esta línea para imprimir el número máximo de frames en cleaned_data\n",
    "    # print(\n",
    "    #     \"Max frames in cleaned_data:\",\n",
    "    #     cleaned_data[\"frame\"].max(),\n",
    "    #     \"for participant_id:\",\n",
    "    #     row[\"participant_id\"],\n",
    "    #     \"and sequence_id:\",\n",
    "    #     row[\"sequence_id\"],\n",
    "    # )\n",
    "\n",
    "    # # Visualizar como esta compuesta cleaned_data\n",
    "    # print(\n",
    "    #         \"cleaned_data:\",\n",
    "    #         cleaned_data,\n",
    "    #         cleaned_data.shape,\n",
    "    #         cleaned_data.columns,\n",
    "    #         cleaned_data[\"frame\"].max(),\n",
    "    #         cleaned_data[\"frame\"].min(),\n",
    "    #         cleaned_data[\"frame\"].unique(),\n",
    "    #         cleaned_data[\"frame\"].value_counts())\n",
    "    # # Dividir y guardar los datos en archivos .npy\n",
    "    train_data, val_data = data_processor.split_data(\n",
    "        cleaned_data, config.TRAIN_RATIO\n",
    "    )\n",
    "    data_processor.save_npy_file(\n",
    "        train_data,\n",
    "        f\"{config.NPY_DATA_PATH}{row['participant_id']}_{row['sequence_id']}_train.npy\",\n",
    "    )\n",
    "    data_processor.save_npy_file(\n",
    "        val_data,\n",
    "        f\"{config.NPY_DATA_PATH}{row['participant_id']}_{row['sequence_id']}_val.npy\",\n",
    "    )\n",
    "\n",
    "    # Almacenar la información en los diccionarios\n",
    "    participant_id = row[\"participant_id\"]\n",
    "    if participant_id not in train_subjects_data:\n",
    "        train_subjects_data[participant_id] = {\"n_points\": 0, \"n_frames\": set()}\n",
    "\n",
    "    if participant_id not in val_subjects_data:\n",
    "        val_subjects_data[participant_id] = {\"n_points\": 0, \"n_frames\": set()}\n",
    "\n",
    "    train_subjects_data[participant_id][\"n_points\"] += len(train_data)\n",
    "    train_subjects_data[participant_id][\"n_frames\"].update(\n",
    "        np.unique(train_data[:, 1])\n",
    "    )\n",
    "\n",
    "    val_subjects_data[participant_id][\"n_points\"] += len(val_data)\n",
    "    val_subjects_data[participant_id][\"n_frames\"].update(np.unique(val_data[:, 1]))\n",
    "\n",
    "utils.save_dict_to_csv(train_subjects_data, config.TRAIN_SUBJECTS_DATA_PATH)\n",
    "utils.save_dict_to_csv(val_subjects_data, config.VAL_SUBJECTS_DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
